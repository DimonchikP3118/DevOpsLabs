# Лабораторная работа №2

## Цель

1. Написать **«плохой» Dockerfile** с несколькими проблемами (bad practices).  
2. Написать **«хороший» Dockerfile**, исправляющий эти проблемы.  

---

## «Плохой» Dockerfile

```dockerfile
# bad_practices/Dockerfile
FROM ubuntu:latest

RUN apt-get update
RUN apt-get install -y python3 python3-pip

WORKDIR /app

ADD . /app

RUN pip3 install -r requirements.txt

CMD python3 main.py

---

## The good one (+ комменты с правками)
FROM python:3.11-slim

# рабочая директория
WORKDIR /app

# системные пакеты устанавливаем одним слоем, очищаем кэш
RUN apt-get update \
    && apt-get install -y --no-install-recommends curl \
    && rm -rf /var/lib/apt/lists/*

# сначала копируем только зависимости для более эффективной работы кэша
COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

# затем копируем остальной код
COPY . .

# создаём непривилегированного пользователя и запускаемся от него
RUN useradd -m appuser
USER appuser

CMD ["python", "main.py"]

# готово

---

## Разбор bad practices в «bad» Dockerfile

1. **Общий образ и тег `latest`**

   ```dockerfile
   FROM ubuntu:latest
   ```

   * Образ Ubuntu тяжёлый.
   * Тег `latest` не гарантирует одинаковую версию при каждой сборке.

   **Решение:**

   ```dockerfile
   FROM python:3.11-slim
   ```

   Лёгкий образ с зафиксированной версией Python.

2. **Разделённые `RUN` и отсутствие очистки кэша**

   ```dockerfile
   RUN apt-get update
   RUN apt-get install -y python3 python3-pip
   ```

   * Обновление индекса и установка пакетов выполняются в разных слоях.
   * Кеш пакетного менеджера не очищается.

   **Решение:**

   ```dockerfile
   RUN apt-get update \
       && apt-get install -y --no-install-recommends curl \
       && rm -rf /var/lib/apt/lists/*
   ```

   Один слой - меньше мусора.

3. **Использование `ADD` вместо `COPY`**

   ```dockerfile
   ADD . /app
   ```

   * `ADD` умеет распаковывать архивы и скачивать по URL, но здесь это не используется.

   **Решение:**

   ```dockerfile
   COPY requirements.txt .
   COPY . .
   ```

   Явное копирование файлов и лучшая работа кэша.

4. **Запуск от root по умолчанию**

   В «плохом» варианте контейнер запускается от root, пользователь явно не задаётся.

   **Решение (в «хорошем» Dockerfile):**

   ```dockerfile
   RUN useradd -m appuser
   USER appuser
   CMD ["python", "main.py"]
   ```

   Приложение запускается от непривилегированного пользователя.

---

## Bad practices при работе с контейнерами

### 1. Привилегированный запуск

**Пример:**

```bash
docker run --privileged -v /:/host myapp:1.0
```

* `--privileged` даёт контейнеру почти полный доступ к системе.
* Монтирование `/` внутрь контейнера открывает доступ ко всей файловой системе хоста.

**Почему опасно:** любая уязвимость в приложении может привести к повреждению системы или утечке данных.

**Решение:**

* Не использовать `--privileged` без реальной необходимости.
* Монтировать только нужные директории и по возможности в режиме `ro` (только чтение).

---

### 2. Ручные изменения внутри запущенного контейнера

**Пример:**

```bash
docker run -d --name web myapp:1.0
docker exec -it web bash
apt-get install nano
pip install some-new-lib
```

* Изменения не описаны в Dockerfile — второй такой контейнер не воспроизвести.
* После пересоздания контейнера все правки исчезнут.
* Конфигурация становится непредсказуемой.

**Решение:**

* Все изменения фиксировать в Dockerfile или docker-compose.
* После правок пересобирать образ и запускать новые контейнеры из него.

---

## Вывод

В лабораторной работе были подготовлены примеры «плохого» и «хорошего» Dockerfile. Показано, как выбор базового образа, организация слоёв, использование `COPY` вместо `ADD` и запуск приложения от непривилегированного пользователя влияют на размер, безопасность и воспроизводимость образа.


---

# Лабораторная работа №2* (*)

## Цель

1. Написать **«плохой» docker-compose файл** с несколькими bad practices.
2. Написать **«хороший» docker-compose файл**, где эти практики исправлены.
4. В «хорошем» файле настроить сервисы так, чтобы контейнеры запускались вместе, но **не «видели» друг друга по сети**.

---

## 1. «Плохой» docker-compose.yml

```
version: "3.9"

services:
  frontend:
    image: nginx:latest
    ports:
      - "80:80"
    depends_on:
      - database

  database:
    image: mysql:latest
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: appdb
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin123
    ports:
      - "3306:3306"
```
---

## 2. «Хороший» docker-compose.yml

Исправленный вариант, в котором устранены замеченные проблемы и настроена сетевая изоляция сервисов:

```
version: "3.9"

services:
  frontend:
    image: nginx:1.25-alpine
    networks:
      - frontend_net
    ports:
      - "127.0.0.1:8080:80"
    depends_on:
      - database

  database:
    image: mysql:8.0
    networks:
      - database_net
    env_file:
      - db.env
    ports:
      - "127.0.0.1:3306:3306"

networks:
  frontend_net:
    driver: bridge
  database_net:
    driver: bridge
```
---

## 3. Разбор bad practices

### 3.1. Использование тега `latest` и неопределённые версии образов

**В плохом варианте:**

```
image: nginx:latest
...
image: mysql:latest
```

* Тег `latest` не фиксирует версию образа. В разное время `docker compose pull` может подтянуть разные варианты nginx и mysql.

**В хорошем варианте:**

```
image: nginx:1.25-alpine
...
image: mysql:8.0
```

* Версии образов указаны явно, что делает окружение предсказуемым.
* Использование `alpine`- варианта nginx уменьшает размер образа.

**Преимущества:** проще отлаживать ошибки и обновлять версии осознанно.

---

### 3.2. Публикация портов на все интерфейсы хоста

**В плохом варианте:**

```
ports:
  - "80:80"
...
ports:
  - "3306:3306"
```

Если не указать IP-адрес, порты пробрасываются на интерфейсы хоста:

* веб-сервис доступен по HTTP с любых машин, имеющих доступ к хосту.

**В хорошем варианте:**

```
ports:
  - "127.0.0.1:8080:80"
...
ports:
  - "127.0.0.1:3306:3306"
```

* Порты назначаются только на `127.0.0.1`, то есть доступны только с локальной машины.
* Для веб-сервиса используется порт 8080 на хосте, чтобы не занимать 80-й.

**Преимущества:** уменьшается поверхность атаки, БД и nginx не попадают во внешнюю сеть напрямую.

---

### 3.3. Хранение паролей в открытом виде в compose-файле

**В плохом варианте:**

```
environment:
  MYSQL_ROOT_PASSWORD: root
  MYSQL_DATABASE: appdb
  MYSQL_USER: admin
  MYSQL_PASSWORD: admin123
```

* Пароли и логины записаны в явном виде в `docker-compose.yml`.
* Этот файл часто хранится в системе контроля версий, то есть повышается риск утечки конфиденциальной информации.
* Менять пароли неудобно: нужно править конфигурационный файл.

**В хорошем варианте:**

```
env_file:
  - db.env
```

А в `db.env` лежат сами значения:

```env
MYSQL_ROOT_PASSWORD=strong_root_password
MYSQL_DATABASE=appdb
MYSQL_USER=appuser
MYSQL_PASSWORD=strong_app_password
```

**Преимущества:**

* Файл с переменными окружения можно не коммитить, хранить отдельно или управлять им через менеджер секретов.
* Пароли можно менять, не редактируя compose-конфигурацию.

---

### 3.4. Отсутствие явной сетевой сегментации

В «плохом» варианте блок `networks` вообще отсутствует:

* Docker Compose по умолчанию создаёт одну общую сеть для проекта.
* Контейнеры `frontend` и `database` оказываются в этой сети и видят друг друга по имени.

По заданию требуется, чтобы контейнеры не "видели" друг друга по сети, но поднимались вместе:

**В хорошем варианте:**

```
networks:
  frontend_net:
    driver: bridge
  database_net:
    driver: bridge
```

и привязка сервисов:

```
frontend:
  ...
  networks:
    - frontend_net

database:
  ...
  networks:
    - database_net
```

**Преимущества:**

* У `frontend` и `database` нет общей docker-сети.
* Пакеты не могут переместиться напрямую между этими сетями.

---

## 4. Принцип сетевой изоляции контейнеров

В «хорошем» `docker-compose.yml` описаны две отдельные сети:

```
networks:
  frontend_net:
    driver: bridge
  database_net:
    driver: bridge
```

Docker для каждой такой сети создаёт свой bridge-интерфейс и выделяет диапазон IP-адресов. Контейнер:

* подключённый к `frontend_net`, получает адрес только в этой сети;
* подключённый к `database_net`, получает адрес только в другой сети.

В нашей конфигурации:

* контейнер `frontend` подключён только к `frontend_net`;
* контейнер `database` подключён только к `database_net`.

Общей сети у них нет, тогда:

* `ping database` из контейнера `frontend` не сработает;
* `mysql -h frontend` из контейнера `database` тоже не сработает.

При этом:

* оба контейнера по-прежнему поднимаются одной командой `docker compose up`;
* они доступны с хоста через порты на `127.0.0.1`.

##Победа :)

---

## Вывод

В части лабораторной работы со * подготовлены «плохой» и «хороший» варианты `docker-compose.yml` для связки `frontend` (nginx) и `database` (MySQL).
Заметим, что фиксация версий образов, привязка портов к `127.0.0.1`, вынос переменных окружения в `env`-файл и разнесение сервисов по разным сетям повышают безопасность, управляемость и предсказуемость многоконтейнерного окружения, при этом сохраняя возможность запускать все сервисы одной командой.



